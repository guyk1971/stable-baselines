{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from functools import partial\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "# import plotly.express as px\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "display(HTML('<style>.container { width:90% !important; }</style>')) \n",
    "pd.set_option('display.max_columns', None)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/gkoren2/share/Data/MLA/DTT/scarlet/experiments'\n",
    "# data_path='D:\\\\MLA\\\\Data\\\\DTT\\\\Scarlet\\\\experiments'\n",
    "sorted(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, pattern):\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Explore specific esif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder_name='rl_greedy_1'\n",
    "folder_name=os.path.join(data_path,folder_name)\n",
    "esif_file=find('*_esif.csv',os.path.join(data_path,folder_name))[0]\n",
    "score_file=find('*.xlsx',folder_name)[0]\n",
    "print(esif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)\n",
    "xlf=xldf[(xldf.Run_number==1)]\n",
    "# fn_prefix = [trace[0]+'_'+x.strftime('%H:%M:%S').split(':')[0] for x in xlf['start_time']]   # e.g. ['cinebench_23', 'cinebench_08']\n",
    "xlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esif_df=pd.read_csv(esif_file)\n",
    "esif_df['timestamp']=pd.to_datetime(esif_df['timestamp'])\n",
    "esif_df.sort_values(by= 'timestamp').reset_index(inplace=True)\n",
    "esif_df.loc[:,['MMIO_PL1','MMIO_PL2']] = esif_df.loc[:,['MMIO_PL1','MMIO_PL2']]/1000\n",
    "print(esif_df.shape)\n",
    "esif_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esif_df.loc[:,['POWER','tj','tskin','MMIO_PL1','MMIO_PL2']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esif_df.loc[15000,'File_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame_esif(data_filters):\n",
    "    tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "    ips_cols=['cpu{}_inst_delta'.format(i) for i in range(8)]\n",
    "    data_df=pd.DataFrame(columns=['p','tj','tskn','ips'])\n",
    "\n",
    "    for filt in data_filters:   # e.g. filt = {'folders':['rl_rnd_64_3','rl_rnd_8'],'traces':[('cinebench',120),('cinebench',30)]}\n",
    "        for folder in filt['folders']:   # folder = 'rl_rnd_64_3'\n",
    "            fpath=os.path.join(data_path,folder)\n",
    "            esif_file=find('*_esif.csv',fpath)[0]\n",
    "            tat_file=find('*_TAT.csv',fpath)[0]\n",
    "            score_file=find('*.xlsx',fpath)[0]\n",
    "            xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)           \n",
    "            print('='*30,'analyzing esif',esif_file,'='*30)\n",
    "            esif_df=pd.read_csv(esif_file)\n",
    "            esif_df['ips']=esif_df.loc[:,ips_cols].mean(axis=1)\n",
    "            # extract the data from the esif according to the 'traces'\n",
    "            for trace in filt['traces']:   # e.g. trace = ('cinebench',120)\n",
    "                # find the rows of the 1st run of this filter. there might be more than one \n",
    "                print('-'*20,'analyzing trace',trace,'-'*20)\n",
    "                xlf=xldf[((xldf.trace_name==trace[0]) & (xldf.num_of_sec_between==trace[1]) & (xldf.Run_number==1))]\n",
    "                fn_prefix = [trace[0]+'_'+x.strftime('%H:%M:%S').split(':')[0] for x in xlf['start_time']]   # e.g. ['cinebench_23', 'cinebench_08']\n",
    "                for fnp in fn_prefix:\n",
    "#                     print('~'*10,'collecting file',fnp,'~'*10)\n",
    "                    fnp_filt=lambda x: (fnp in x)\n",
    "                    tj= esif_df.loc[esif_df['File_name'].apply(fnp_filt),'tj'].values\n",
    "                    tskn= esif_df.loc[esif_df['File_name'].apply(fnp_filt),'tskin'].values\n",
    "                    p=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'POWER'].values\n",
    "                    ips=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'ips'].values\n",
    "\n",
    "                    tj_nm1=tj[:-1]\n",
    "                    tj_n=tj[1:]\n",
    "                    ts_nm1=tskn[:-1]\n",
    "                    ts_n=tskn[1:]\n",
    "                    p_n=p[1:]\n",
    "                    p_nm1=p[:-1]\n",
    "                    ips_n=ips[1:]\n",
    "                    ips_nm1=ips[:-1]\n",
    "                    print('folder',folder,' trace',trace,' file prefix',fnp,'found {} samples'.format(len(p_n)))\n",
    "                    data_df=data_df.append(pd.DataFrame({'p_n':p_n,'tj_n':tj_n,'tskn_n':ts_n,'ips_n':ips_n,\n",
    "                                                         'p_nm1':p_nm1,'tj_nm1':tj_nm1,'tskn_nm1':ts_nm1,\n",
    "                                                         'ips_nm1':ips_nm1}),ignore_index=True)\n",
    "#                     print('~'*10,'done with file',fnp,'~'*10)\n",
    "#                 print('-'*20,'done with trace', trace,'-'*20)\n",
    "            print('='*30,'done with esif',folder,'='*30)\n",
    "        # clean the ips\n",
    "        q999=data_df['ips_n'].quantile(0.999)\n",
    "        data_df['ips_n']=data_df['ips_n'].apply(lambda x: min(x,q999))\n",
    "        q999=data_df['ips_nm1'].quantile(0.999)\n",
    "        data_df['ips_nm1']=data_df['ips_nm1'].apply(lambda x: min(x,q999))\n",
    "        print('total samples:',len(data_df))\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame_tat(data_filters):\n",
    "    tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "    ips_cols=['cpu{}_inst_delta'.format(i) for i in range(8)]\n",
    "    data_df=pd.DataFrame(columns=['p','tj','tskn','tmem'])\n",
    "\n",
    "    for filt in data_filters:   # e.g. filt = {'folders':['rl_rnd_64_3','rl_rnd_8'],'traces':[('cinebench',120),('cinebench',30)]}\n",
    "        for folder in filt['folders']:   # folder = 'rl_rnd_64_3'\n",
    "            fpath=os.path.join(data_path,folder)\n",
    "            esif_file=find('*_esif.csv',fpath)[0]\n",
    "            tat_file=find('*_TAT.csv',fpath)[0]\n",
    "            score_file=find('*.xlsx',fpath)[0]\n",
    "            xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)           \n",
    "            print('='*30,'analyzing tat',tat_file,'='*30)\n",
    "            tat_df=pd.read_csv(tat_file)\n",
    "#             esif_df['ips']=esif_df.loc[:,ips_cols].mean(axis=1)\n",
    "            # extract the data from the esif according to the 'traces'\n",
    "            for trace in filt['traces']:   # e.g. trace = ('cinebench',120)\n",
    "                # find the rows of the 1st run of this filter. there might be more than one \n",
    "                print('-'*20,'analyzing trace',trace,'-'*20)\n",
    "                xlf=xldf[((xldf.trace_name==trace[0]) & (xldf.num_of_sec_between==trace[1]) & (xldf.Run_number==1))]\n",
    "                fn_prefix = [trace[0]+'_'+x.strftime('%H:%M:%S').split(':')[0] for x in xlf['start_time']]   # e.g. ['cinebench_23', 'cinebench_08']\n",
    "                for fnp in fn_prefix:\n",
    "#                     print('~'*10,'collecting file',fnp,'~'*10)\n",
    "                    fnp_filt=lambda x: (fnp in x)\n",
    "                    tj= tat_df.loc[tat_df['File_name'].apply(fnp_filt),'tj'].values\n",
    "                    tskn= tat_df.loc[tat_df['File_name'].apply(fnp_filt),'TSKN-temp(Degree C)'].values\n",
    "                    tmem= tat_df.loc[tat_df['File_name'].apply(fnp_filt),'TMEM-temp(Degree C)'].values \n",
    "                    p=tat_df.loc[tat_df['File_name'].apply(fnp_filt),'POWER'].values\n",
    "#                     ips=esif_df.loc[tat_df['File_name'].apply(fnp_filt),'ips'].values\n",
    "\n",
    "                    tj_nm1=tj[:-1]\n",
    "                    tj_n=tj[1:]\n",
    "                    ts_nm1=tskn[:-1]\n",
    "                    ts_n=tskn[1:]\n",
    "                    tm_nm1=tmem[:-1]\n",
    "                    tm_n=tmem[1:]\n",
    "\n",
    "                    p_n=p[1:]\n",
    "                    p_nm1=p[:-1]\n",
    "#                     ips_n=ips[1:]\n",
    "#                     ips_nm1=ips[:-1]\n",
    "                    print('folder',folder,' trace',trace,' file prefix',fnp,'found {} samples'.format(len(p_n)))\n",
    "                    data_df=data_df.append(pd.DataFrame({'p_n':p_n,'tj_n':tj_n,'tskn_n':ts_n,'tm_n':tm_n,'tm_nm1':tm_nm1,\n",
    "                                                         'p_nm1':p_nm1,'tj_nm1':tj_nm1,'tskn_nm1':ts_nm1}),ignore_index=True)\n",
    "#                     print('~'*10,'done with file',fnp,'~'*10)\n",
    "#                 print('-'*20,'done with trace', trace,'-'*20)\n",
    "            print('='*30,'done with tat',folder,'='*30)\n",
    "        # clean the ips\n",
    "#         q999=data_df['ips_n'].quantile(0.999)\n",
    "#         data_df['ips_n']=data_df['ips_n'].apply(lambda x: min(x,q999))\n",
    "#         q999=data_df['ips_nm1'].quantile(0.999)\n",
    "#         data_df['ips_nm1']=data_df['ips_nm1'].apply(lambda x: min(x,q999))\n",
    "        print('total samples:',len(data_df))\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test models\n",
    "in this section we train models to predict:\n",
    "- Tj given power\n",
    "- ips mean given power\n",
    "- Tskin given Tj\n",
    "- Tmem given Tj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb15\n",
    "# train_data=[{'folders':['rl_rnd_64','rl_rnd_64_3','rl_rnd_64_4','rl_rnd_64_5','rl_rnd_64_6','psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1'],'traces':[('cinebench',300),('cinebench',240),('cinebench',180),('cinebench',120),('cinebench',90),('cinebench',60),('cinebench',30),('cinebench',1)]}]\n",
    "# test_data =[{'folders':['rl_rnd_7','rl_rnd_8','psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',240),('cinebench',180),('cinebench',120),('cinebench',90),('cinebench',60),('cinebench',30),('cinebench',1)]}] \n",
    "# cb20\n",
    "train_data=[{'folders':['rl_rnd_64','rl_rnd_64_3','rl_rnd_64_4','rl_rnd_64_5','rl_rnd_64_6','psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1'],'traces':[('cb20',300),('cb20',240),('cb20',180),('cb20',120),('cb20',90),('cb20',60),('cb20',30),('cb20',1)]}]\n",
    "test_data =[{'folders':['rl_rnd_7','rl_rnd_8','psvt_at-9_25_45_64-base_1'],'traces':[('cb20',300),('cb20',240),('cb20',180),('cb20',120),('cb20',90),('cb20',60),('cb20',30),('cb20',1)]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trndf=get_data_frame_esif(train_data)\n",
    "tstdf=get_data_frame_esif(test_data)\n",
    "# p_n=trndf['p_n'].values\n",
    "# tj_n=trndf['tj_n'].values\n",
    "# tskn_n=trndf['tskn_n'].values\n",
    "# p_nm1=trndf['p_nm1'].values\n",
    "# tj_nm1=trndf['tj_nm1'].values\n",
    "# tskn_nm1=trndf['tskn_nm1'].values\n",
    "# ips_n=trndf['ips_n'].values\n",
    "# ips_nm1=trndf['ips_nm1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tj (power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "p_n=trndf['p_n'].values\n",
    "tj_n=trndf['tj_n'].values\n",
    "tj_nm1=trndf['tj_nm1'].values\n",
    "tjfit2=LinearRegression().fit(np.array([p_n,tj_nm1]).T,tj_n)\n",
    "print(tjfit2.coef_)\n",
    "print(tjfit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "p_n=tstdf['p_n'].values\n",
    "tj_n=tstdf['tj_n'].values\n",
    "tj_nm1=tstdf['tj_nm1'].values\n",
    "tjest2=np.minimum(tjfit2.predict(np.array(np.array([p_n,tj_nm1]).T)),102)\n",
    "tstdf['tjest2']=tjest2\n",
    "# tjest3=np.minimum(np.array([np.ones_like(p_n),p_n,tj_nm1]).T.dot(np.insert(tjfit2.coef_,0,tjfit2.intercept_)),100)\n",
    "# tstdf['tjest3']=tjest3\n",
    "# tstdf.loc[:,['tj_n','tjest2','tjest3']].plot(figsize=(8,4),grid=True)\n",
    "tstdf.loc[:,['tj_n','tjest2']].plot(figsize=(8,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tskn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[{'folders':['psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1','psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),\n",
    "                                                                                              ('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}]\n",
    "test_data =[{'folders':['psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),\n",
    "                                                              ('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}] \n",
    "\n",
    "trndf=get_data_frame_esif(train_data)\n",
    "tstdf=get_data_frame_esif(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tj_n=trndf['tj_n'].values\n",
    "tskn_n=trndf['tskn_n'].values\n",
    "tj_nm1=trndf['tj_nm1'].values\n",
    "tskn_nm1=trndf['tskn_nm1'].values\n",
    "tsfit2=LinearRegression().fit(np.array([tj_n,tj_nm1,tskn_nm1]).T,tskn_n)\n",
    "print(tsfit2.coef_)\n",
    "print(tsfit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tj_n=tstdf['tj_n'].values\n",
    "tskn_n=tstdf['tskn_n'].values\n",
    "tj_nm1=tstdf['tj_nm1'].values\n",
    "tskn_nm1=tstdf['tskn_nm1'].values\n",
    "tskest2=tsfit2.predict(np.array([tj_n,tj_nm1,tskn_nm1]).T)\n",
    "tstdf['tskest2']=tskest2\n",
    "tstdf.loc[:,['tskn_n','tskest2']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model ips_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[{'folders':['psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1','psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),\n",
    "                                                                                              ('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}]\n",
    "test_data =[{'folders':['psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),\n",
    "                                                              ('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}] \n",
    "\n",
    "trndf=get_data_frame_esif(train_data)\n",
    "tstdf=get_data_frame_esif(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### At Idle time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# find ips in idle periods\n",
    "plt.plot(ips_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idle=(ips_n<1e8)\n",
    "plt.plot(p_n[idle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "ipsfit2=LinearRegression().fit(np.array([p_n[idle],p_nm1[idle],ips_nm1[idle]]).T,ips_n[idle])\n",
    "print(ipsfit2.coef_)\n",
    "print(ipsfit2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### over all period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "p_n=trndf['p_n'].values\n",
    "p_nm1=trndf['p_nm1'].values\n",
    "ips_n=trndf['ips_n'].values\n",
    "ips_nm1=trndf['ips_nm1'].values\n",
    "ipsfit2=LinearRegression().fit(np.array([p_n,p_nm1,ips_nm1]).T,ips_n)\n",
    "print(ipsfit2.coef_)\n",
    "print(ipsfit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "p_n=tstdf['p_n'].values\n",
    "p_nm1=tstdf['p_nm1'].values\n",
    "ips_n=tstdf['ips_n'].values\n",
    "ips_nm1=tstdf['ips_nm1'].values\n",
    "\n",
    "ipsest2=tsfit2.predict(np.array([p_n,p_nm1,ips_nm1]).T)\n",
    "tstdf['ipsest2']=ipsest2\n",
    "tstdf.loc[:,['ips_n','ipsest2']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tmem \n",
    "currently from tat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=[{'folders':['psvt_at-9_25_45_64-fixed_1'],'traces':[('cb20',60)]}]\n",
    "# train_data=[{'folders':['psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1',],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1)]}]\n",
    "train_data=[{'folders':['psvt_at-9_25_45_64-fixed_1','psvt_at-9_25_45_64-greedy_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}]\n",
    "\n",
    "# test_data =[{'folders':['psvt_at-9_25_45_64-base_1'],'traces':[('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}] \n",
    "# test_data =[{'folders':['psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1)]}] \n",
    "test_data =[{'folders':['psvt_at-9_25_45_64-base_1'],'traces':[('cinebench',300),('cinebench',180),('cinebench',120),('cinebench',60),('cinebench',30),('cinebench',1),\n",
    "                                                              ('cb20',300),('cb20',180),('cb20',120),('cb20',60),('cb20',30),('cb20',1)]}] \n",
    "\n",
    "trndf=get_data_frame_tat(train_data)\n",
    "tstdf=get_data_frame_tat(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tj_n=trndf['tj_n'].values\n",
    "tmem_n=trndf['tm_n'].values\n",
    "tj_nm1=trndf['tj_nm1'].values\n",
    "tmem_nm1=trndf['tm_nm1'].values\n",
    "p_n=trndf['p_n'].values\n",
    "p_nm1=trndf['p_nm1'].values\n",
    "tmfit2=LinearRegression().fit(np.array([tj_n,tj_nm1,tmem_nm1]).T,tmem_n)\n",
    "# tmfit2=LinearRegression().fit(np.array([p_n,p_nm1,tmem_nm1]).T,tmem_n)\n",
    "print(tmfit2.coef_)\n",
    "print(tmfit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tj_n=tstdf['tj_n'].values\n",
    "tmem_n=tstdf['tm_n'].values\n",
    "tj_nm1=tstdf['tj_nm1'].values\n",
    "tmem_nm1=tstdf['tm_nm1'].values\n",
    "p_n=tstdf['p_n'].values\n",
    "p_nm1=tstdf['p_nm1'].values\n",
    "tmest2=tmfit2.predict(np.array([tj_n,tj_nm1,tmem_nm1]).T)\n",
    "# tmest2=tmfit2.predict(np.array([p_n,p_nm1,tmem_nm1]).T)\n",
    "tstdf['tmest2']=tmest2\n",
    "tstdf.loc[:,['tm_n','tmest2']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Extraction\n",
    "In this section we run the simulator to get statistics over the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proj_root=os.path.dirname(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,proj_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from train.custom_envs import DTTEnvSim,PLATFORMS\n",
    "from train.dttsim_wrappers import DTTStateRewardWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "platform = PLATFORMS['Scarlet']\n",
    "print(platform.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "workload_params = 10*(['cb15']+['cooldown']*60) +\\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10*(['cb20']+['cooldown']*60) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10*(['cb15']+['cooldown']*45) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10 * (['cb20'] + ['cooldown'] * 45) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10 * (['cb15'] + ['cooldown'] * 30) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10 * (['cb20'] + ['cooldown'] * 30) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10 * (['cb15'] + ['cooldown'] * 15) + \\\n",
    "                  ['cooldown'] * 150 + \\\n",
    "                  10 * (['cb20'] + ['cooldown'] * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = DTTEnvSim(platform, workload_params=workload_params, norm_obs=False,log_output=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wenv=DTTStateRewardWrapper(env,n_frames=5,n_features=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward\n",
    "In this section we'll try to find a model to predict the score.\n",
    "We'll develop a simple model per benchmark that is based on aggregated features (statistics gathered throughout the benchmark execution).   \n",
    "\n",
    "Relevant features:\n",
    " - IPS mean\n",
    " - IPS stdev\n",
    " - Clip Reason events histogram (how many occurences of each reason will be a distinct feature)\n",
    " - some information about the turbo budget\n",
    "     - % time below threshold - this will probably be more informative\n",
    "     - avegare turbo budget level ? will not tell a lot. \n",
    "\n",
    "Let's start with that and develop a model for cb15 and cb20.  \n",
    "\n",
    "first, start with common tools\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_score_tid(xldf,tt):\n",
    "    score=0\n",
    "    trace='_idle'\n",
    "#     start_time=tt.strftime('%Y-%m-%d %H-%M-%S')\n",
    "#     start_time='1900-01-01 00:00:00'\n",
    "    sc=xldf.loc[(xldf['start_time']<tt) & (xldf['end_time']>tt) ,['score','trace_name','num_of_sec_between','start_time']].values\n",
    "    if len(sc)>0:\n",
    "        score=sc[0][0]\n",
    "        trace=sc[0][1]+'_'+str(sc[0][2])+'_'+str(sc[0][3])\n",
    "#         start_time=str(sc[0][3])\n",
    "    return score,trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_for_reward(data_filters):\n",
    "    tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "    ips_cols=['cpu{}_inst_delta'.format(i) for i in range(8)]\n",
    "    # tid = trace_id = trace name + start time\n",
    "    data_df=pd.DataFrame(columns=['ts','tid','power','pl1','pl2','clip','ips','score'])\n",
    "    for filt in data_filters:   # e.g. filt = {'folders':['rl_rnd_64_3','rl_rnd_8'],'traces':[('cinebench',120),('cinebench',30)]}\n",
    "        for folder in filt['folders']:   # folder = 'rl_rnd_64_3'\n",
    "            fpath=os.path.join(data_path,folder)\n",
    "            # extract file names\n",
    "            esif_file=find('*_esif.csv',fpath)[0]\n",
    "            tat_file=find('*_TAT.csv',fpath)[0]\n",
    "            score_file=find('*.xlsx',fpath)[0]\n",
    "            # read excel (score)\n",
    "            xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)           \n",
    "            print('='*30,'analyzing esif',esif_file,'='*30)\n",
    "            # read esif file\n",
    "            esif_df=pd.read_csv(esif_file)\n",
    "            esif_df['timestamp']=pd.to_datetime(esif_df['timestamp'])\n",
    "            esif_df.sort_values(by= 'timestamp').reset_index(inplace=True)\n",
    "            esif_df.loc[:,['MMIO_PL1','MMIO_PL2']] = esif_df.loc[:,['MMIO_PL1','MMIO_PL2']]/1000\n",
    "            # add turbo budget calc\n",
    "            esif_df['ewma']=(esif_df['MMIO_PL1'] - esif_df['POWER']).ewm(com=27.5, adjust=False).mean()\n",
    "            # add information about the trace name and score\n",
    "            tid_score_extract=partial(get_score_tid,xldf)\n",
    "            esif_df['score']=0\n",
    "            esif_df['trace_name']=''\n",
    "            esif_df.loc[:,['score','trace_name']]=np.array([[a,b] for a,b in esif_df['timestamp'].apply(tid_score_extract)])\n",
    "            # calc ips stats\n",
    "            esif_df['ips']=esif_df.loc[:,ips_cols].mean(axis=1)\n",
    "            # extract the data from the esif according to the 'traces'\n",
    "            for trace in filt['traces']:   # e.g. trace = ('cinebench',120)\n",
    "                # find the rows of the 1st run of this filter. there might be more than one \n",
    "                print('-'*20,'analyzing trace',trace,'-'*20)\n",
    "                xlf=xldf[((xldf.trace_name==trace[0]) & (xldf.num_of_sec_between==trace[1]) & (xldf.Run_number==1))]\n",
    "#                 fn_prefix = [trace[0]+'_'+x.strftime('%H:%M:%S').split(':')[0] for x in xlf['start_time']]   # e.g. ['cinebench_23', 'cinebench_08']\n",
    "                # Note : the file name includes the time it was opened whereas the start time in the xlsx is where the benchmark actually started to run\n",
    "                # we open the file and then wait the 5 minutes between runs so to get the prefix of filename we have to reduce 5 min from the benchmark start time\n",
    "                fn_prefix = [trace[0]+'_'+(x-timedelta(minutes=5)).strftime('%H:%M:%S').split(':')[0] for x in xlf['start_time']]   # e.g. ['cinebench_23', 'cinebench_08']\n",
    "                for fnp in fn_prefix:\n",
    "#                     print('~'*10,'collecting file',fnp,'~'*10)\n",
    "                    fnp_filt=lambda x: (fnp in x)\n",
    "                    ts = esif_df.loc[esif_df['File_name'].apply(fnp_filt),'timestamp'].values \n",
    "                    tid=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'trace_name'].values\n",
    "                    pl1= esif_df.loc[esif_df['File_name'].apply(fnp_filt),'MMIO_PL1'].values\n",
    "                    pl2= esif_df.loc[esif_df['File_name'].apply(fnp_filt),'MMIO_PL2'].values\n",
    "                    p=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'POWER'].values\n",
    "                    clip=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'IA Clip'].values\n",
    "                    ips=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'ips'].values\n",
    "                    score=esif_df.loc[esif_df['File_name'].apply(fnp_filt),'score'].values.astype(float)\n",
    "                    print('folder',folder,' trace',trace,' file prefix',fnp,'found {} samples'.format(len(p)))\n",
    "                    data_df=data_df.append(pd.DataFrame({'ts':ts,'tid':tid,'power':p,'pl1':pl1,'pl2':pl2,'clip':clip,'ips':ips,'score':score}),ignore_index=True)\n",
    "#                     print('~'*10,'done with file',fnp,'~'*10)\n",
    "#                 print('-'*20,'done with trace', trace,'-'*20)\n",
    "            print('='*30,'done with esif',folder,'='*30)\n",
    "        ############## post processing for the whole data frame ##############\n",
    "        # clean the ips\n",
    "        q999=data_df['ips'].quantile(0.999)\n",
    "        data_df['ips']=data_df['ips'].apply(lambda x: min(x,q999))\n",
    "        # 1-hot encoding for the IA Clip column\n",
    "        ccn=['clip_{}'.format(i) for i in reversed(range(16))]\n",
    "        data_df=data_df.reindex(columns=list(data_df.columns)+ccn)\n",
    "        data_df.loc[:,ccn]=data_df['clip'].apply(lambda v: [int(b) for b in \"{:016b}\".format((v & 0xffff))]).to_list()\n",
    "        # for easy drawing, label encode the clip:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        data_df['clip'] = data_df['clip'].apply(lambda x: x & 0xffff)\n",
    "        data_df['clip'] = 10* le.fit_transform(data_df['clip'])\n",
    "        ccd={10*c:hex(le.classes_[c]) for c in range(len(le.classes_))}\n",
    "        print('total samples:',len(data_df))\n",
    "        print('clip code', ccd)\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing ###\n",
    "folder_name='psvt_at-9_25_45_64-fixed_1'\n",
    "folder_name=os.path.join(data_path,folder_name)\n",
    "esif_file=find('*_esif.csv',os.path.join(data_path,folder_name))[0]\n",
    "tat_file=find('*_TAT.csv',os.path.join(data_path,folder_name))[0]\n",
    "score_file=find('*.xlsx',folder_name)[0]\n",
    "\n",
    "esif_df=pd.read_csv(esif_file)\n",
    "esif_df['timestamp']=pd.to_datetime(esif_df['timestamp'])\n",
    "esif_df=esif_df.sort_values(by= 'timestamp')\n",
    "esif_df.reset_index(inplace=True)\n",
    "\n",
    "tslog_parser = lambda x: datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)\n",
    "esif_df.columns\n",
    "\n",
    "# tt=esif_df.loc[29800,'timestamp']\n",
    "# get_trace_score_start(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_score_extract=partial(get_score_tid,xldf)\n",
    "esif_df['score']=0\n",
    "esif_df['trace_name']=''\n",
    "esif_df.loc[:,['score','trace_name']]=np.array([[a,b] for a,b in esif_df['timestamp'].apply(tid_score_extract)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esif_df['trace_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esif_df['trace_name'].apply(lambda x: x.startswith('cb20_1')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt=esif_df.loc[795,'timestamp']\n",
    "# sc,_=get_score_tid(xldf,tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tat_df=pd.read_csv(tat_file)\n",
    "tat_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb20\n",
    "sec_between=[300,240,180,120,90,60,30,1]\n",
    "traces=[('cb20',k) for k in sec_between]\n",
    "train_data=[{'folders':['rl_rnd_64_3','fixed_25_64','psvt_at-9_25_45_64-base_1','psvt_at-9_25_45_64-fixed_1'],'traces':[('cb20',k) for k in sec_between]}]\n",
    "test_data =[{'folders':['rl_rnd_64','rl_rnd_7','rl_rnd_8','psvt_at-9_25_45_64-greedy_1'],'traces':[('cb20',k) for k in sec_between]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb15\n",
    "sec_between=[300,240,180,120,90,60,30,1]\n",
    "traces=[('cinebench',k) for k in sec_between]\n",
    "train_data=[{'folders':['rl_rnd_64_3','rl_rnd_64_5','rl_rnd_64_6','fixed_25_64','psvt_at-9_25_45_64-base_1','psvt_at-9_25_45_64-fixed_1'],'traces':[('cinebench',k) for k in sec_between]}]\n",
    "test_data =[{'folders':['rl_rnd_64','rl_rnd_7','rl_rnd_8','psvt_at-9_25_45_64-greedy_1'],'traces':[('cinebench',k) for k in sec_between]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the train data\n",
    "trndf=get_data_for_reward(train_data)\n",
    "gbtr=trndf.groupby('tid')\n",
    "tid_groups=list(gbtr.groups.keys())\n",
    "tid_groups\n",
    "# tstdf=get_data_for_reward(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to explore specific signal\n",
    "g0=gbtr.get_group(tid_groups[1])\n",
    "g0[['power','pl1','clip']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf=gbtr.mean()\n",
    "fdf.loc[fdf['score']!=0,:].plot.scatter('ips','score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "sc_vs_ips = fdf.loc[fdf['score']!=0,['ips','score']]\n",
    "scfit=LinearRegression().fit(sc_vs_ips['ips'].values[:,None],sc_vs_ips['score'].values)\n",
    "# tmfit2=LinearRegression().fit(np.array([p_n,p_nm1,tmem_nm1]).T,tmem_n)\n",
    "print(scfit.coef_)\n",
    "print(scfit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tstdf=get_data_for_reward(test_data)\n",
    "gbtst=tstdf.groupby('tid')\n",
    "tidg=list(gbtst.groups.keys())\n",
    "tidg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# draw some signal\n",
    "g0=gbtst.get_group(tidg[1])\n",
    "g0[['power','pl1','clip']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fdf_tst=gbtst.mean()\n",
    "sc_vs_ips_tst = fdf_tst.loc[fdf_tst['score']!=0,['ips','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scest=scfit.predict(sc_vs_ips_tst['ips'].values[:,None])\n",
    "sc_vs_ips_tst['scest']=scest\n",
    "# sc_vs_ips.loc[:,['score','scest']].plot.scatter('scest','score')\n",
    "# sc_vs_ips.plot.scatter('ips',['score','scest'])\n",
    "ax1 = sc_vs_ips_tst.plot(kind='scatter', x='ips', y='score', color='r')    \n",
    "ax2 = sc_vs_ips_tst.plot(kind='scatter', x='ips', y='scest', color='g', ax=ax1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reward Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this function doesnt work well. need to figure out why\n",
    "def get_data_for_reward2(data_filters):\n",
    "    tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "    ips_cols=['cpu{}_inst_delta'.format(i) for i in range(8)]\n",
    "    # tid = trace_id = trace name + start time\n",
    "    data_df=pd.DataFrame(columns=['ts','tid','power','pl1','pl2','clip','ips','score'])\n",
    "    for filt in data_filters:   # e.g. filt = {'folders':['rl_rnd_64_3','rl_rnd_8'],'traces':[('cinebench',120),('cinebench',30)]}\n",
    "        for folder in filt['folders']:   # folder = 'rl_rnd_64_3'\n",
    "            fpath=os.path.join(data_path,folder)\n",
    "            # extract file names\n",
    "            esif_file=find('*_esif.csv',fpath)[0]\n",
    "            tat_file=find('*_TAT.csv',fpath)[0]\n",
    "            score_file=find('*.xlsx',fpath)[0]\n",
    "            # read excel (score)\n",
    "            xldf = pd.read_excel(score_file,  parse_dates = ['start_time', 'end_time'], date_parser = tslog_parser)           \n",
    "            print('='*30,'analyzing esif',esif_file,'='*30)\n",
    "            # read esif file\n",
    "            esif_df=pd.read_csv(esif_file)\n",
    "            esif_df['timestamp']=pd.to_datetime(esif_df['timestamp'])\n",
    "            esif_df.sort_values(by= 'timestamp').reset_index(inplace=True)\n",
    "            esif_df.loc[:,['MMIO_PL1','MMIO_PL2']] = esif_df.loc[:,['MMIO_PL1','MMIO_PL2']]/1000\n",
    "            # add turbo budget calc\n",
    "            esif_df['ewma']=(esif_df['MMIO_PL1'] - esif_df['POWER']).ewm(com=27.5, adjust=False).mean()\n",
    "            # add information about the trace name and score\n",
    "            tid_score_extract=partial(get_score_tid,xldf)\n",
    "            esif_df['score']=0\n",
    "            esif_df['trace_name']=''\n",
    "            esif_df.loc[:,['score','trace_name']]=np.array([[a,b] for a,b in esif_df['timestamp'].apply(tid_score_extract)])\n",
    "            # calc ips stats\n",
    "            esif_df['ips']=esif_df.loc[:,ips_cols].mean(axis=1)\n",
    "            # extract the data from the esif according to the 'traces'\n",
    "            for trace in filt['traces']:   # e.g. trace = ('cinebench',120)\n",
    "                print('-'*20,'analyzing trace',trace,'-'*20)\n",
    "                tn = trace[0]+'_'+str(trace[1])    # e.g. 'cinebench_120'\n",
    "#                 tn_filt=lambda x: (tn in x)\n",
    "                tn_filt=lambda x: x.startswith(tn)\n",
    "                ts = esif_df.loc[esif_df['trace_name'].apply(tn_filt),'timestamp'].values \n",
    "                tid=esif_df.loc[esif_df['trace_name'].apply(tn_filt),'trace_name'].values\n",
    "                pl1= esif_df.loc[esif_df['trace_name'].apply(tn_filt),'MMIO_PL1'].values\n",
    "                pl2= esif_df.loc[esif_df['trace_name'].apply(tn_filt),'MMIO_PL2'].values\n",
    "                p=esif_df.loc[esif_df['trace_name'].apply(tn_filt),'POWER'].values\n",
    "                clip=esif_df.loc[esif_df['trace_name'].apply(tn_filt),'IA Clip'].values\n",
    "                ips=esif_df.loc[esif_df['trace_name'].apply(tn_filt),'ips'].values\n",
    "                score=esif_df.loc[esif_df['trace_name'].apply(tn_filt),'score'].values.astype(float)\n",
    "                print('folder',folder,' trace',trace,' file prefix',tn,'found {} samples'.format(len(p)))\n",
    "#                 set_trace()\n",
    "                data_df=data_df.append(pd.DataFrame({'ts':ts,'tid':tid,'power':p,'pl1':pl1,'pl2':pl2,'clip':clip,'ips':ips,'score':score}),ignore_index=True)\n",
    "#                 print('-'*20,'done with trace', trace,'-'*20)\n",
    "            print('='*30,'done with esif',folder,'='*30)\n",
    "        ############## post processing for the whole data frame ##############\n",
    "        # clean the ips\n",
    "        q999=data_df['ips'].quantile(0.999)\n",
    "        data_df['ips']=data_df['ips'].apply(lambda x: min(x,q999))\n",
    "        # 1-hot encoding for the IA Clip column\n",
    "        ccn=['clip_{}'.format(i) for i in reversed(range(16))]\n",
    "        data_df=data_df.reindex(columns=list(data_df.columns)+ccn)\n",
    "        data_df.loc[:,ccn]=data_df['clip'].apply(lambda v: [int(b) for b in \"{:016b}\".format((v & 0xffff))]).to_list()\n",
    "        # for easy drawing, label encode the clip:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        data_df['clip'] = data_df['clip'].apply(lambda x: x & 0xffff)\n",
    "        data_df['clip'] = 10* le.fit_transform(data_df['clip'])\n",
    "        ccd={10*c:hex(le.classes_[c]) for c in range(len(le.classes_))}\n",
    "        print('total samples:',len(data_df))\n",
    "        print('clip code', ccd)\n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tstdf2=get_data_for_reward2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tstdf2['tid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gbtst2=tstdf2.groupby('tid')\n",
    "tidg2=list(gbtst2.groups.keys())\n",
    "tidg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g2=gbtst2.get_group(tidg2[1])\n",
    "g2[['power','pl1','clip']].plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluate Fidelity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parser\n",
    "Avishai's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import seaborn as sns\n",
    "df_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "df1= pd.read_csv(os.path.join(data_path,'exp1/etl_output_esif.csv'), parse_dates=['timestamp'] ,date_parser=df_parser)\n",
    "df2= pd.read_csv(os.path.join(data_path,'exp2/etl_output_esif.csv'), parse_dates=['timestamp'] ,date_parser=df_parser)\n",
    "df3= pd.read_csv(os.path.join(data_path,'exp3/etl_output_esif.csv'), parse_dates=['timestamp'] ,date_parser=df_parser)\n",
    "df4= pd.read_csv(os.path.join(data_path,'exp4/etl_output_esif.csv'), parse_dates=['timestamp'] ,date_parser=df_parser)\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df.sort_values(by= 'timestamp', inplace = True)\n",
    "\n",
    "df['cpu0_delta'] = df['cpu0'].diff(1).fillna(0)\n",
    "df['cpu1_delta'] = df['cpu1'].diff(1).fillna(0)\n",
    "df['cpu2_delta'] = df['cpu2'].diff(1).fillna(0)\n",
    "df['cpu3_delta'] = df['cpu3'].diff(1).fillna(0)\n",
    "df['cpu4_delta'] = df['cpu4'].diff(1).fillna(0)\n",
    "df['cpu5_delta'] = df['cpu5'].diff(1).fillna(0)\n",
    "df['cpu6_delta'] = df['cpu6'].diff(1).fillna(0)\n",
    "df['cpu7_delta'] = df['cpu7'].diff(1).fillna(0)\n",
    "\n",
    "list_of_cpus = ['cpu0_delta', 'cpu1_delta', 'cpu2_delta', 'cpu3_delta', 'cpu4_delta', 'cpu5_delta', 'cpu6_delta', 'cpu7_delta']\n",
    "\n",
    "df = df[df.cpu0_delta>0]\n",
    "df = df[df.cpu1_delta>0]\n",
    "df = df[df.cpu2_delta>0]\n",
    "\n",
    "df = df[df.cpu3_delta>0]\n",
    "df = df[df.cpu4_delta>0]\n",
    "df = df[df.cpu5_delta>0]\n",
    "df = df[df.cpu6_delta>0]\n",
    "df = df[df.cpu7_delta>0]\n",
    "\n",
    "\n",
    "df['cpu_avg'] = df[list_of_cpus].apply(lambda row: row.mean(), axis = 1)\n",
    "df['cpu_max'] = df[list_of_cpus].apply(lambda row: row.max(), axis = 1)\n",
    "\n",
    "tslog_parser = lambda x: pd.datetime.strptime(x, '%B%d %H:%M:%S')\n",
    "\n",
    "score_data_path = data_path+'/*/DTT1*.xlsx'\n",
    "all_ts_logs_path = list(glob.iglob(score_data_path, recursive=True))\n",
    "df_tslog = []\n",
    "for file in all_ts_logs_path:\n",
    "    df_tslog.append(pd.read_excel(file , parse_dates=['start_time', 'end_time'] ,date_parser=tslog_parser))\n",
    "\n",
    "df_tslog = pd.concat(df_tslog)\n",
    "\n",
    "score_and_ips = {'score': [], 'ips_avg': [],  'trace_name': [], 'num_of_sec_between': [], 'pl1': [], 'tskin': []}\n",
    "for i in range(len(df_tslog.start_time)):\n",
    "        find_run_index = (df.timestamp >= df_tslog.start_time.iloc[i]) & (df.timestamp <= df_tslog.end_time.iloc[i])\n",
    "        df.loc[find_run_index, 'File_name'] = df_tslog['trace_name'].iloc[i] + '_' + str(df_tslog.index[i]) + '_' + str(df_tslog['bursty_pl2'].iloc[i])\n",
    "        score_and_ips['score'].append(df_tslog.score.iloc[i])\n",
    "        data_temp = df[df.File_name ==  df_tslog['trace_name'].iloc[i] + '_' + str(df_tslog.index[i]) + '_' + str(df_tslog['bursty_pl2'].iloc[i])].reset_index(drop=True)\n",
    "        score_and_ips['ips_avg'].append(data_temp['cpu_avg'].mean())\n",
    "        score_and_ips['trace_name'].append( df_tslog['trace_name'].iloc[i])\n",
    "        score_and_ips['num_of_sec_between'].append( df_tslog['num_of_sec_between'].iloc[i])\n",
    "        score_and_ips['pl1'].append( df_tslog['bursty_pl2'].iloc[i])\n",
    "        score_and_ips['tskin'].append( data_temp['tskin'].max())\n",
    "\n",
    "\n",
    "score_and_ips = pd.DataFrame(score_and_ips)\n",
    "\n",
    "score_and_ips['pl_sns'] = score_and_ips['pl1']\n",
    "score_and_ips['pl_sns'][score_and_ips['pl_sns'] == 64000] = 4\n",
    "score_and_ips['pl_sns'][score_and_ips['pl_sns'] == 60000] = 3\n",
    "score_and_ips['pl_sns'][score_and_ips['pl_sns'] == 44000] = 2\n",
    "score_and_ips['pl_sns'][score_and_ips['pl_sns'] == 24000] = 1\n",
    "\n",
    "score_cinebench = score_and_ips[(score_and_ips.trace_name == 'cinebench') &(score_and_ips.num_of_sec_between == 300)]\n",
    "score_cinebench1 = score_and_ips[(score_and_ips.trace_name == 'cinebench') &(score_and_ips.num_of_sec_between == 1)]\n",
    "score_DCC = score_and_ips[(score_and_ips.trace_name == 'pcmark10_DCC') &(score_and_ips.num_of_sec_between == 300)]\n",
    "score_pcmark10_essentials = score_and_ips[(score_and_ips.trace_name == 'pcmark10_essentials') &(score_and_ips.num_of_sec_between == 300)]\n",
    "score_pcmark10_gaming = score_and_ips[(score_and_ips.trace_name == 'pcmark10_gaming') &(score_and_ips.num_of_sec_between == 300)]\n",
    "score_pcmark10_productivity = score_and_ips[(score_and_ips.trace_name == 'pcmark10_productivity') &(score_and_ips.num_of_sec_between == 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_cinebench, x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_cinebench1, x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_DCC, x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_pcmark10_essentials, x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_pcmark10_gaming , x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = score_pcmark10_productivity , x= 'score', y = 'ips_avg', hue = 'pl_sns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
